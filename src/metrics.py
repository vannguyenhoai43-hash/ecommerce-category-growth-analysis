# -*- coding: utf-8 -*-
"""metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1okFJqORBNkdbjXyjubAQdjOLC_-JE0OA
"""

# Format số
def format_num(val):
    """Hàm định dạng số: 1,000,000 hoặc +10%"""
    if pd.isna(val): return "0"
    return f"{val:+,.0f}"
# Format %
def format_pct(val):
    """Hàm định dạng phần trăm"""
    if pd.isna(val): return "0%"
    return f"{val:+.2%}"
# Format về lable
def growth_lable(val):
  if val > 0:
    return "tăng"
  elif val < 0:
    return "giảm"
  else:
    return "ổn định"

"""## Phần 1: Tổng quan

###Hàm tăng trưởng
"""

# Hàm tính tăng trưởng
def _growth(df_cat):

  ado_m = df_cat['ADO_M'].sum()
  ado_m1 = df_cat['ADO_M_1'].sum()
  gmv_m = df_cat['AdGMV_M'].sum()
  gmv_m1 = df_cat['AdGMV_M_1'].sum()

  return {
  'diff_ado' : ado_m - ado_m1,
  'diff_gmv' : gmv_m - gmv_m1,
  'grow_ado' : (ado_m - ado_m1) / ado_m1  if ado_m1 != 0 else 0,
  'grow_gmv':(gmv_m - gmv_m1) / gmv_m1  if gmv_m1 != 0 else 0,
}

# hàm tăng trưởng nhiều level
def growth_by_mul_level(df, level_cols):
    results = []

    base_col = ['ADO_M','ADO_M_1','AdGMV_M','AdGMV_M_1']

    for level_values, sub_df in df.groupby(level_cols):

        # tính growth cho từng group
        res = _growth(sub_df)

        # Giữ lại base col
        for c in base_col:
          res[c]=sub_df[c].sum()

        # gắn lại từng level vào kết quả
        for col, val in zip(level_cols, level_values):
            res[col] = val

        results.append(res)

    return pd.DataFrame(results)

"""### Hàm keywords"""

noise_phrases = [
    # Marketing / bán hàng
    'sale off',
    'bán chạy',
    'thanh lý',
    'chính hãng',
    'giá rẻ',
    'cao cấp',
    'hỏa tốc','bảo hành'

    # Thuộc tính / mô tả
    'đa năng',
    'kim loại',
    'chi tiết',
    'khổ rộng',
    'dạng sóng',
    'lấy ánh sáng',
    'hai đầu',
    'dễ thương',
    'đáng yêu',
    'ánh sáng',
    'tự động',

    # Trạng thái / phạm vi
    'ngẫu nhiên',
    'tất cả',
    'bao gồm',
    'hàng loại 1',

    # Thương hiệu / sàn / địa danh
    'shopee',
    'shopee mall',
    'made in',
    'sài gòn',
    'hà nội',
    'ib shop','gù salaya'

    # Năm
    '2017', '2018', '2019',
    '2020', '2021', '2022',
    '2023', '2024', '2025'
]

noise_words = {
    # Đơn vị đo lường & thông số kỹ thuật
    'v', 'w', 'mah', 'ah', 'mm', 'cm', 'm', 'kg', 'g',
    'lít', 'ml', 'inch', 'size',
    '12v', '24v', '220v', '60w', '100w', '120w',

    # Hình thức đóng gói & số lượng
    'cái', 'chiếc', 'viên', 'hộp', 'thùng', 'gói',
    'cặp', 'đôi', 'set', 'lố', 'bịch', 'cuộn',
    'mét', 'tấm', 'miếng', 'sợi',
    'que', 'cây', 'chai', 'lọ', 'tuýp', 'bình','sỉ','lẻ','viền',
    # Vị trí & hướng
    'trước', 'sau', 'trái', 'phải',
    'trên', 'dưới', 'trong', 'ngoài',
    'giữa', 'bên', 'ngang', 'dọc',
    'đứng', 'nằm', 'gầm', 'hậu',

    # Hành động / mục đích
    'dành', 'cho', 'của', 'lắp', 'độ', 'chế',
    'thay', 'thế', 'sửa', 'chữa',
    'làm', 'tẩy', 'rửa', 'xịt', 'bôi',
    'trơn', 'đánh', 'bóng', 'dán', 'ốp',
    'che', 'đựng', 'treo', 'móc', 'giữ', 'nối', 'nhận','cách','ghi','miễn',

    # Tính chất chung
    'chuyên', 'dụng', 'mini', 'nhỏ', 'lớn', 'to',
    'zin', 'xịn', 'nhập', 'khẩu', 'nội', 'địa',
    'loại', 'tốt', 'dày', 'mọi','qsmotor',

    # Màu sắc
    'đen', 'trắng', 'đỏ', 'xanh', 'vàng',
    'bạc', 'tím', 'hồng', 'cam',
    'nâu', 'xám', 'màu', 'trong', 'suốt',

    # Marketing
    'sale', 'off', 'hot', 'new',
    'mới', 'giảm', 'giá', 'rẻ',
    'siêu', 'free', 'freeship',
    'tặng', 'kèm', 'top', 'best', 'trend',

    # Khác
    'phụ', 'kiện', 'linh', 'đồ', 'nghề', 'cụ',
    'thiết', 'bị', 'hơi', 'nước', 'khí', 'nén',
    'nhà', 'cửa', 'gia', 'đình',
    'full', 'nhiều', 'mẫu', 'đủ'
}

import re
import pandas as pd
import unicodedata

def clean_and_shorten(name, num_keywords=5):
    if pd.isna(name):
        return ''
    # 1. remove keycap emoji
    name = re.sub(r'[\d]\ufe0f?\u20e3', ' ', name)

    # 2. remove emoji khác
    name = re.sub(r'[\U0001F300-\U0001FAFF]', ' ', name)

    # 3. Normalize unicode nhưng KHÔNG encode ascii
    name = unicodedata.normalize('NFKC', name)

    # 4. Lowercase
    name = name.lower()

    # 5. Bỏ nội dung trong ngoặc
    name = re.sub(r'[\(\[\{].*?[\)\]\}]', ' ', name)

    # 6. Remove phrase trước (sale off, chính hãng...)
    for phrase in noise_phrases:
        name = re.sub(rf'\b{re.escape(phrase)}\b', ' ', name)

    # 7. Replace underscore bằng space
    name = name.replace('_', ' ')

    # 8. Remove emoji & ký tự đặc biệt (GIỮ tiếng Việt)
    name = re.sub(r'[^\w\sàáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ]', ' ', name)

    # 9. Split & remove noise word (1 từ)
    words = name.split()
    keywords = [w for w in words if w not in noise_words]

    # 10. Remove duplicate – giữ thứ tự
    seen = set()
    unique_keywords = []
    for w in keywords:
        if w not in seen:
            seen.add(w)
            unique_keywords.append(w)

    return ' '.join(unique_keywords[:num_keywords])

"""## Phần 2: Phân tích động lực tăng trưởng

### Cat tăng
"""

# Hàm cat đóng góp nhiều nhất
def highest_contrib(df, metric):

    if metric == 'ado':
        contrib_col = 'contrib_ado'
        diff_col = 'diff_ado'
    elif metric == 'gmv':
        contrib_col = 'contrib_gmv'
        diff_col = 'diff_gmv'
    else:
        raise ValueError("Invalid metric. Must be 'ado' or 'gmv'.")

    result = []

    for lvl1, sub_df in df.groupby('level1_kpi_category'):

        # Tổng toàn bộ
        total_contrib = sub_df[contrib_col].sum()
        total_diff = sub_df[diff_col].sum()

        # Top 3
        top3 = (
            sub_df
            .sort_values(contrib_col, ascending=False)
            .head(3)
            [['level1_kpi_category','level2_kpi_category', diff_col, contrib_col]]
        )

        # Tổng top 3
        top3_contrib = top3[contrib_col].sum()
        top3_diff = top3[diff_col].sum()

        # Other = total - top3
        others_row = pd.DataFrame([{
            'level1_kpi_category': lvl1,
            'level2_kpi_category': 'Others',
            diff_col: total_diff - top3_diff,
            contrib_col: total_contrib - top3_contrib
        }])

        result.append(pd.concat([top3, others_row], ignore_index=True))

    return pd.concat(result, ignore_index=True)



"""## Phần 3: Chất lượng tăng trưởng"""



"""## Phần 4: Xu hướng ngành hàng"""

